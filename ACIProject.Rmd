---
title: "ACIProject"
author: "Mandy Simpson"
date: "18/10/2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Predicting income from census data

## Introduction

The project is part of the HarvardX Profeessional Certificate in Data Science Course, PH:125.9x - Capstone.

For the self-directoed project I chose to explore the Adult Census Income dataset ("ACI") from University of California at Irvine, which can be found at <https://www.kaggle.com/uciml/adult-census-income>.  This dataset was originally derived from the US Census Bureau 1994 database.  It includes an indicator column showing whether the individual described by that entry earned under or over $50k. It is this indicator that I am seeking to predict using the other information in the dataset. 

I started the project by exploring the full dataset to ensure I understood the information contained. While the data was already broadly clean, and in tidy format, I removed some rows with missing data, and stratified the data in areas such as age, and education level. 

Once this was complete, I split the dataset into training and validation sets (90%/10%), and then split the training set further into training and test sets (80%/20%), to allow a number of algorithms to be trialled on this data before selecting one for use on the validation set. 

# Downloading and preprocessing the Adult Census Income dataset

The file can be downloaded from github at <https://github.com/mandysimpson/adult-census-income/raw/master/adult.csv>

```{r download, message=FALSE, warning=FALSE}
#install packages
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(dplyr)) install.packages("dplyr", repos = "http://cran.us.r-project.org")

#download file
adult_census_income <- read.csv("https://github.com/mandysimpson/adult-census-income/raw/master/adult.csv")
```

The ACI dataset has `r nrow(adult_census_income)` observations each representing an individual person in the census. 

There are `r ncol(adult_census_income)` attributes as follows:

Name               | Type                | Description                               |
-------------------|---------------------|-------------------------------------------|
age                | Integer             | Age of respondent                         |
workclass          | Factor (9 levels)   | Employer type                             |
fnlwgt             | Integer             | Population weighting factor               |
education          | Factor (16 levels)  | Highest education level achieved          |
education.num      | Integer             | Numerical representation of education     |
marital.status     | Factor (7 levels)   | Marital Status of respondent              |
occupation         | Factor (15 levels)  | Type of employment                        |
relationship       | Factor (6 levels)   | Position in household                     |
race               | Factor (5 levels)   | Race of respondent                        |
sex                | Factor (2 levels)   | Sex of respondent                         |
capital.gain       | Integer             | Investment gains                          |
capital.loss       | Integer             | Investment losses                         |
hours.per.week     | Integer             | Working hours                             |
native.country     | Factor (42 levels)  | Country of birth                          |
income             | Factor (2 levels)   | Income under or over $50k                 |

A number of observations include missing data in the `workclass`, `occupation` and `native.country` attributes - represented by a "?". I removed these from the data set.

```{r remove_missing_data, warning=FALSE, message=FALSE}
aci <- filter(adult_census_income, !workclass == "?", !occupation == "?", !native.country == "?")
aci <- droplevels(aci)
```
This removes `r nrow(adult_census_income) - nrow(aci)` rows, leaving `r nrow(aci)`. 

For observations remaining in the dataset, `r round(mean(aci$income == ">50K") * 100,2)`% indicate an income of over 50k.

## Deleting unnecessary attributes

The attribute `fnlwgt` is a measure of the units of population represented by this observation. As such it doesn't seem likely to be relevant for determining income. To check this I plotted fnlwgt against income. 

```{r plot_fnlwgt, echo=FALSE}
aci %>% ggplot(aes(income,fnlwgt)) + geom_boxplot()
```

There appears to be very little difference, and so I deleted this attribute. On inspection, the attributes `education` and `education.num` appear to be the same, with `education.num` being a numerical representation of `education`. I therefore also deleted `education`.

```{r delete_fnlwgt_education, warning=FALSE, message=FALSE}
aci <- aci %>% select(-c(fnlwgt,education))
```

I next ran the `nearZeroVar` function of the `caret` package to understand which attributes could be removed due to minimal variance. 

```{r nearzero}
nzv <- nearZeroVar(aci)
```

The function recomends the removal of the `capital.gain`, `capital.loss` and `native.country` attributes. On inspection we can see that `r round(mean(aci$capital.gain == 0)*100,2)`% of the `capital.gain` values and `r round(mean(aci$capital.loss == 0)*100,2)`% of the `capital.loss` values are actually 0, and that `r round(mean(aci$native.country == "United-States")*100,2)`% of the `native.country` values are "United-States".

I therefore removed these attributes from the dataset.
```{r remove_capital_gain_loss_native_country}
aci <- aci %>% select(-c(capital.gain,capital.loss,native.country))
```

We're left with 9 predictors for the income attribute.

# Visualising the data

## Age

I created a density plot showing the count of age range split by income.

```{r plot_age, echo=FALSE, message=FALSE, warning=FALSE}
aci %>% ggplot(aes(age, y = ..count.., fill = income)) + geom_density(alpha = 0.6)
```

We can see significant differences in the data. While there is no age at which the proportion earning over 50k increases above 50%, the proportion does increase with age. For under 25's the proportion is just 1.19% while for those between 45-49 it is 39.49%.

##Workclass 

For the workclass attribute I used a bar graph showing the split of each workclass factor by income. 

```{r plot_workclass, echo=FALSE, message=FALSE, warning=FALSE}
aci %>% ggplot(aes(workclass, fill = income)) + geom_bar()
```

The workclass "Private" is by far the biggest, making up `r round(mean(aci$workclass == "Private")*100,2)`% of the total. 

Drawing this bar graph again by proportion shows that greater than 50% of the `Self-emp-inc` group has income over 50k - in fact this is 55.87%

```{r plot_workclass_perc, echo=FALSE, message=FALSE, warning=FALSE}
aci %>% ggplot(aes(workclass, fill = income)) + geom_bar(position = "fill") + labs(y = "proportion")
```

## Education

For the education attribute I used a bar graph showing the split of each education level by income, in this case using proportion view straight away. 

```{r plot_education_num, echo=FALSE, message=FALSE, warning=FALSE}
aci %>% ggplot(aes(education.num, y = ..count.., fill = income)) + geom_bar(position = "fill") + labs(y = "proportion")
```

Unsurprisingly as education levels increase so does the proportion of people earning over 50k.


## Marital Status

For this attribute I again used a bar graph showing the split by income. 

```{r plot_marital, echo=FALSE, message=FALSE, warning=FALSE}
aci %>% ggplot(aes(marital.status, fill = income)) + geom_bar(position = "fill") + labs(y = "proportion") + scale_x_discrete(labels = abbreviate)
```

What we seem to see here is a strong difference in the proportions of higher incomes for someone who is married (with their spouse present):

Marital Status         | % over 50K |
-----------------------|------------|
Married-civ-spouse     | 45.50      |
Married-AF-spouse      | 47.62      |
-----------------------|------------|
Divorced               | 14.06      |
Married-spouse-absent  |  8.38      |
Never-married          |  4.83      |
Separated              |  7.03      |
Widowed                |  9.67      |

I wondered whether this might be different for each sex:

```{r plot_marital_v_sex, echo=FALSE, message=FALSE, warning=FALSE}
aci %>% ggplot(aes(marital.status, fill = income)) + geom_bar(position = "fill") + labs(y = "proportion") + scale_x_discrete(labels = abbreviate) + facet_grid(sex ~ .)
```

They appear broadly similar, although What we do see is that the proportion of female respondents earning more than 50k is even more clearly delineated across the categories with spouse present and those without. 

## Occupation

Again I plotted this on a proportion basis by income

```{r plot_occupation, echo=FALSE, message=FALSE, warning=FALSE}
aci %>% ggplot(aes(occupation, fill = income)) + geom_bar(position = "fill") + labs(y = "proportion") + scale_x_discrete(labels = abbreviate)
```

There is a lot of variance across these, with the highest being "Exec-managerial" and "Prof-specialty".

## Relationship

I wasn't sure from the documentation of this dataset, what connection (if any) there is between `relationship`, `marital.status` and `sex`.

```{r plot_relationship, echo=FALSE, message=FALSE, warning=FALSE}
aci %>% ggplot(aes(relationship, fill = income)) + geom_bar(position = "fill") + labs(y = "proportion") + scale_x_discrete(labels = abbreviate)
```

Here it seems that the `relationship` attribute is repeating the information we gained from the `marital.status` attribute, at least for those describing themselves as "Husband" or "Wife" - these are 100% contained in the Married-AF-spouse and "Married-civ-spouse" categories.

```{r explore_wife_husband, warning=FALSE, message=FALSE}
aci %>% filter(relationship == "Wife" | relationship == "Husband") %>% group_by(marital.status) %>% summarise(count = n())
```

Given the similarity of these I decided to remove this attribute as well. 

```{r remove_relationship, warning=FALSE, message=FALSE}
aci <- aci %>% select(-relationship)
```

## Race

`r round(mean(aci$race == "White")*100,2)`% of the dataset is "White". The bar chart shows the proportions by income. 

```{r plot_race, echo=FALSE, message=FALSE, warning=FALSE}
aci %>% ggplot(aes(race, fill = income)) + geom_bar(position = "fill") + labs(y = "proportion")
```

There is a significant difference between the income proportion of "White" or "Asian-Pac_Islander" at roughly 25% over 50k and all other races at around half that level. 

## Sex

`r round(mean(aci$sex == "Male")*100,2)`% of the dataset is "Male". The bar chart again shows the proportions by income. 

```{r plot_sex, echo=FALSE, message=FALSE, warning=FALSE}
aci %>% ggplot(aes(sex, fill = income)) + geom_bar(position = "fill") + labs(y = "proportion")
```

Again there is a noticeable difference in income level between sexes with the proportion of "Male" respondents earning over 50k at 31.38%, with "Female" respondents only 11.37%.

## Hours per week

I used a histogram to plot the hours per week data, to allow for the fact that most of the responses are rounded to the nearest 5 hours. 

```{r plot_hours_per_week, echo=FALSE, message=FALSE, warning=FALSE}
aci %>% ggplot(aes(hours.per.week, y = ..count.., fill = income)) + geom_histogram(binwidth = 5, position = "fill") + labs(y = "proportion")
```

As we might expect the proportion of those earning over 50k rises significantly at around 40-50 hours per week, representing the cultural norm of fulltime work. Interestingly it doesn't rise further, as hours continue to go up, and in fact appears to fall slightly.

# Analysis

Firstly I split the dataset (which is now `r nrow(aci)` observations) into training and validation sets. 

```{r split_validation, message=FALSE, warning=FALSE}
set.seed(1,sample.kind = "Rounding")
#if using R3.5 or earlier set.seed(1)

test_index <- createDataPartition(aci$income, times = 1, p = 0.2, list = FALSE)
validation <- aci[test_index, ]
training <- aci[-test_index, ]
```

To enable me to try out a number of different approaches before settling on a final algorithm I also split the training set into training and test. 

```{r split_testing, message=FALSE, warning=FALSE}
set.seed(10,sample.kind = "Rounding")
#if using R3.5 or earlier set.seed(10)

test_index2 <- createDataPartition(training$income, times = 1, p = 0.2, list = FALSE)
testing <- training[test_index2, ]
training <- training[-test_index2, ]
```

The training set now has `r nrow(training)` observations.

## k Nearest Neighbours

I start with a k-nearest neighbours model. I'm not sure what value of k to use so I use the cross-validation built into the caret package on the range 4 to 41. I reduce the default to 10-fold cross validation to reduce the time taken to run. 

```{r knn_selecting_k, message=FALSE, warning=FALSE}
set.seed(3,sample.kind = "Rounding")
#if using R3.5 or earlier set.seed(3)

control <- trainControl(method = "cv", number = 10, p = .9)
train_knn <- train(income ~ ., method = "knn", data = training, tuneGrid = data.frame(k = seq(5,41,2)), trControl = control)
ggplot(train_knn,highlight = TRUE)
train_knn$bestTune
```

I then use this model to make predictions on the testing dataset

```{r knn_predict, message=FALSE, warning=FALSE}
confusionMatrix(predict(train_knn, testing, type = "raw"), testing$income)$overall["Accuracy"]
```

The accuracy is over 80% on the testing set. 

## Random Forest

I considered using Quadratic Discriminant Analysis or Linear Discriminant Analysis, but discarded these approaches due to the number or predictors and the fact that most do not appear normally distributed. Instead I settle on trying a Random Forest algorithm as the second approach. 






# Conclusion

I used the Adult Census Income dataset from UCI to predict income levels as being under or over 50k. Using a Random Forest algorithm I achieved an accuracy level on a randomly selected validation set of xxxxxxx.

Prior to selecting this algorithm I also tested a k nearest neighbours algorithm, achieving an accuracy rate on a reserved (for testing) part of the training set of xxxxxx.  It is possible that further accuracy could be achieved by using an ensemble approach of the kNN and Random Forest algorithms. 

It is also worth considering the possible limitations of this as a predictive algorithm for use outside the Adult Census Income data. The chosen dataset differs to the US population in a number of respects. Notably it has more men, more white people, and fewer immigrants than the standard population, which is currently approximately 51% female, 40% non-white and approximately 28% immigrant (includes US born children). 
